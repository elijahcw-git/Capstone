{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elijahcw-git/Capstone/blob/main/Logistic_Regression_LAPD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !pip install category_encoders"
      ],
      "metadata": {
        "id": "Uf0CIRBH8ocp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46d909e-4903-4cbe-f7a0-4a9e0fa41f1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "5Y_Ixt_B99oe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT7vHUKF8XAm",
        "outputId": "baa8a4d5-0a57-4dff-eb60-8dfac6e68427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2883802, 26)\n"
          ]
        }
      ],
      "source": [
        "#Import dataset:\n",
        "\n",
        "clean_df = pd.read_csv('/content/drive/MyDrive/clean_df_1Mar2024.csv')\n",
        "print(clean_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean_df['Vict_Descent'].unique()"
      ],
      "metadata": {
        "id": "kFtOhuTO3MEZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W1nbrd_jxUB2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print data shape\n",
        "# print(f\"Dataset shape: {clean_df.shape}\\n\")\n",
        "\n",
        "# missing_values = clean_df.isnull().sum()\n",
        "# percentage_missing = (missing_values / len(clean_df)) * 100\n",
        "# unique_values = clean_df.nunique()  # Count unique values in each column\n",
        "\n",
        "# # Creating a DataFrame to display data type, missing values, percentage of missing values, and number of unique values\n",
        "# summary_df = pd.DataFrame({\n",
        "#     'Data_type': clean_df.dtypes,\n",
        "#     'Missing': missing_values,\n",
        "#     '%_Missing': percentage_missing,\n",
        "#     'Unique_values': unique_values  # Adding the unique values count\n",
        "# })\n",
        "\n",
        "# print(summary_df)"
      ],
      "metadata": {
        "id": "Ey1j0mhw59ro"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing data cleaning steps\n",
        "# clean_df = clean_df[~((clean_df['LAT'] == 0) & (clean_df['LON'] == 0))]\n",
        "# clean_df = clean_df[(clean_df['Avg_Windspeed'] <= 80) & (clean_df['Vict_Age'] <= 100)]\n",
        "# clean_df['Vict_Sex'].fillna('Unknown', inplace=True)\n",
        "# clean_df['Vict_Descent'].fillna('Unknown', inplace=True)\n",
        "# clean_df['Total_Precipitation'].fillna(clean_df['Total_Precipitation'].median(), inplace=True)\n",
        "\n",
        "# Function to categorize age into 3 numeric categories\n",
        "def categorize_age(age):\n",
        "    if age < 18:\n",
        "        return 0  # Category for minors\n",
        "    elif age <= 64:\n",
        "        return 1  # Category for adults\n",
        "    else:\n",
        "        return 2  # Category for seniors\n",
        "\n",
        "# Column for age categories\n",
        "clean_df['Vict_Age_Category'] = clean_df['Vict_Age'].apply(categorize_age)"
      ],
      "metadata": {
        "id": "9gr88hEEf1NJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns_to_drop = ['Crm_Cd_1', 'Premis_Cd', 'Premis_Desc','Status', 'Status_Desc']\n",
        "# clean_df.drop(columns=columns_to_drop, inplace=True)\n",
        "# clean_df['Weapon_Reported'] = clean_df['Weapon_Used_Cd'].notna().astype(int)"
      ],
      "metadata": {
        "id": "aoR1M5qbAB2c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the unique value the number count of those unique value.\n",
        "\n",
        "# for column in ['Part_1-2', 'Weapon_Reported','Vict_Sex','Vict_Age_Category']:\n",
        "#   print(f\"Unique values for {column}:\")\n",
        "#   unique_values = clean_df[column].unique()\n",
        "#   for value in unique_values:\n",
        "#     count = clean_df[clean_df[column] == value].shape[0]\n",
        "#     print(f\"  - {value}: {count}\")"
      ],
      "metadata": {
        "id": "U5R5YR0bQeoY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top 10 most frequent Crm_Cd\n",
        "# top_10_crimes = clean_df['Crm_Cd'].value_counts().nlargest(10).index\n",
        "df_top_10_crimes = clean_df\n",
        "# # Filter the dataset to only include rows with the top 10 Crm_Cd\n",
        "# df_top_10_crimes = clean_df[clean_df['Crm_Cd'].isin(top_10_crimes)]\n",
        "\n",
        "# # Print the new dataset shape\n",
        "# print(df_top_10_crimes.shape)\n"
      ],
      "metadata": {
        "id": "xitTzQN7ELJV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning Data to top 10 crimes"
      ],
      "metadata": {
        "id": "pS1089Ut9AW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=df_top_10_crimes\n",
        "\n",
        "# Convert 'Date_Rptd' and 'DATE_OCC' to datetime\n",
        "data['Date_Rptd'] = pd.to_datetime(data['Date_Rptd'])\n",
        "data['DATE_OCC'] = pd.to_datetime(data['DATE_OCC'])\n",
        "\n",
        "# Extract day of week, month, and year from 'DATE_OCC'\n",
        "data['Day_of_Week'] = data['DATE_OCC'].dt.dayofweek\n",
        "data['Month'] = data['DATE_OCC'].dt.month\n",
        "data['Year'] = data['DATE_OCC'].dt.year\n",
        "\n",
        "# Drop the original 'Date_Rptd' and 'DATE_OCC' columns\n",
        "data = data.drop(['Date_Rptd', 'DATE_OCC'], axis=1)\n",
        "\n",
        "# Convert 'Vict_Sex' and 'Vict_Descent' to dummy variables\n",
        "categorical_to_convert = ['Vict_Sex', 'Region_Ethnic_Origin']\n",
        "data = pd.get_dummies(data, columns=categorical_to_convert, drop_first=True)\n",
        "data['Day_of_Week'] = data['Day_of_Week'].astype('category')\n",
        "data['Month'] = data['Month'].astype('category')\n",
        "data['Year'] = data['Year'].astype('category')\n",
        "\n",
        "# Create dummy variables for these columns\n",
        "data = pd.get_dummies(data, columns=['Day_of_Week', 'Month', 'Year'], drop_first=True)\n",
        "\n",
        "\n",
        "# We will not convert 'LOCATION' due to its high cardinality\n",
        "data.drop(['LOCATION','Vict_Age_Category', 'Vict_Descent', 'DR_NO'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "YiOuZErKNuza"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "L3cvEySk3FvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3ada14-15d6-47cc-d94d-16a4827869ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TIME_OCC', 'AREA', 'AREA_NAME', 'Rpt_Dist_No', 'Part_1-2', 'Crm_Cd',\n",
              "       'Crm_Cd_Desc', 'Vict_Age', 'LAT', 'LON', 'Avg_Temp', 'Avg_Dewpoint',\n",
              "       'Avg_Humidity', 'Avg_Windspeed', 'Avg_Pressure', 'Total_Precipitation',\n",
              "       'Crime_Category', 'Crime_Category_Code', 'Weapon_Reported',\n",
              "       'Vict_Sex_M', 'Vict_Sex_X', 'Region_Ethnic_Origin_Black',\n",
              "       'Region_Ethnic_Origin_Hispanic/Latin/Mexican',\n",
              "       'Region_Ethnic_Origin_Other', 'Region_Ethnic_Origin_Unknown',\n",
              "       'Region_Ethnic_Origin_White', 'Day_of_Week_1', 'Day_of_Week_2',\n",
              "       'Day_of_Week_3', 'Day_of_Week_4', 'Day_of_Week_5', 'Day_of_Week_6',\n",
              "       'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7',\n",
              "       'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12', 'Year_2011',\n",
              "       'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015', 'Year_2016',\n",
              "       'Year_2017', 'Year_2018', 'Year_2019', 'Year_2020', 'Year_2021',\n",
              "       'Year_2022', 'Year_2023'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print data shape\n",
        "print(f\"Dataset shape: {data.shape}\\n\")\n",
        "\n",
        "missing_values = data.isnull().sum()\n",
        "percentage_missing = (missing_values / len(data)) * 100\n",
        "unique_values = data.nunique()  # Count unique values in each column\n",
        "non_missing_count = data.count()  # Count non-missing values in each column\n",
        "\n",
        "# Creating a DataFrame to:\n",
        "summary_df = pd.DataFrame({\n",
        "    'Data_type': data.dtypes, # Display data type\n",
        "    'Count': non_missing_count,  # Count of non-missing values\n",
        "    'Missing': missing_values, # Missing values\n",
        "    '%_Missing': percentage_missing, # Percentage of missing values\n",
        "    'Unique_values': unique_values  # Unique values count\n",
        "})\n",
        "\n",
        "print(summary_df)\n"
      ],
      "metadata": {
        "id": "DrBIVPLDON30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289e805e-0c4e-4078-8f9f-eb8f432ee238"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2883802, 56)\n",
            "\n",
            "                                            Data_type    Count  Missing  \\\n",
            "TIME_OCC                                        int64  2883802        0   \n",
            "AREA                                            int64  2883802        0   \n",
            "AREA_NAME                                      object  2883802        0   \n",
            "Rpt_Dist_No                                     int64  2883802        0   \n",
            "Part_1-2                                        int64  2883802        0   \n",
            "Crm_Cd                                          int64  2883802        0   \n",
            "Crm_Cd_Desc                                    object  2883802        0   \n",
            "Vict_Age                                      float64  2883802        0   \n",
            "LAT                                           float64  2883802        0   \n",
            "LON                                           float64  2883802        0   \n",
            "Avg_Temp                                      float64  2883802        0   \n",
            "Avg_Dewpoint                                  float64  2883802        0   \n",
            "Avg_Humidity                                  float64  2883802        0   \n",
            "Avg_Windspeed                                 float64  2883802        0   \n",
            "Avg_Pressure                                  float64  2883802        0   \n",
            "Total_Precipitation                           float64  2883802        0   \n",
            "Crime_Category                                 object  2883802        0   \n",
            "Crime_Category_Code                             int64  2883802        0   \n",
            "Weapon_Reported                                 int64  2883802        0   \n",
            "Vict_Sex_M                                      uint8  2883802        0   \n",
            "Vict_Sex_X                                      uint8  2883802        0   \n",
            "Region_Ethnic_Origin_Black                      uint8  2883802        0   \n",
            "Region_Ethnic_Origin_Hispanic/Latin/Mexican     uint8  2883802        0   \n",
            "Region_Ethnic_Origin_Other                      uint8  2883802        0   \n",
            "Region_Ethnic_Origin_Unknown                    uint8  2883802        0   \n",
            "Region_Ethnic_Origin_White                      uint8  2883802        0   \n",
            "Day_of_Week_1                                   uint8  2883802        0   \n",
            "Day_of_Week_2                                   uint8  2883802        0   \n",
            "Day_of_Week_3                                   uint8  2883802        0   \n",
            "Day_of_Week_4                                   uint8  2883802        0   \n",
            "Day_of_Week_5                                   uint8  2883802        0   \n",
            "Day_of_Week_6                                   uint8  2883802        0   \n",
            "Month_2                                         uint8  2883802        0   \n",
            "Month_3                                         uint8  2883802        0   \n",
            "Month_4                                         uint8  2883802        0   \n",
            "Month_5                                         uint8  2883802        0   \n",
            "Month_6                                         uint8  2883802        0   \n",
            "Month_7                                         uint8  2883802        0   \n",
            "Month_8                                         uint8  2883802        0   \n",
            "Month_9                                         uint8  2883802        0   \n",
            "Month_10                                        uint8  2883802        0   \n",
            "Month_11                                        uint8  2883802        0   \n",
            "Month_12                                        uint8  2883802        0   \n",
            "Year_2011                                       uint8  2883802        0   \n",
            "Year_2012                                       uint8  2883802        0   \n",
            "Year_2013                                       uint8  2883802        0   \n",
            "Year_2014                                       uint8  2883802        0   \n",
            "Year_2015                                       uint8  2883802        0   \n",
            "Year_2016                                       uint8  2883802        0   \n",
            "Year_2017                                       uint8  2883802        0   \n",
            "Year_2018                                       uint8  2883802        0   \n",
            "Year_2019                                       uint8  2883802        0   \n",
            "Year_2020                                       uint8  2883802        0   \n",
            "Year_2021                                       uint8  2883802        0   \n",
            "Year_2022                                       uint8  2883802        0   \n",
            "Year_2023                                       uint8  2883802        0   \n",
            "\n",
            "                                             %_Missing  Unique_values  \n",
            "TIME_OCC                                           0.0           1439  \n",
            "AREA                                               0.0             21  \n",
            "AREA_NAME                                          0.0             21  \n",
            "Rpt_Dist_No                                        0.0           1302  \n",
            "Part_1-2                                           0.0              2  \n",
            "Crm_Cd                                             0.0            144  \n",
            "Crm_Cd_Desc                                        0.0            144  \n",
            "Vict_Age                                           0.0             99  \n",
            "LAT                                                0.0           5634  \n",
            "LON                                                0.0           5131  \n",
            "Avg_Temp                                           0.0            333  \n",
            "Avg_Dewpoint                                       0.0            496  \n",
            "Avg_Humidity                                       0.0            720  \n",
            "Avg_Windspeed                                      0.0            161  \n",
            "Avg_Pressure                                       0.0             21  \n",
            "Total_Precipitation                                0.0             98  \n",
            "Crime_Category                                     0.0              8  \n",
            "Crime_Category_Code                                0.0              8  \n",
            "Weapon_Reported                                    0.0              2  \n",
            "Vict_Sex_M                                         0.0              2  \n",
            "Vict_Sex_X                                         0.0              2  \n",
            "Region_Ethnic_Origin_Black                         0.0              2  \n",
            "Region_Ethnic_Origin_Hispanic/Latin/Mexican        0.0              2  \n",
            "Region_Ethnic_Origin_Other                         0.0              2  \n",
            "Region_Ethnic_Origin_Unknown                       0.0              2  \n",
            "Region_Ethnic_Origin_White                         0.0              2  \n",
            "Day_of_Week_1                                      0.0              2  \n",
            "Day_of_Week_2                                      0.0              2  \n",
            "Day_of_Week_3                                      0.0              2  \n",
            "Day_of_Week_4                                      0.0              2  \n",
            "Day_of_Week_5                                      0.0              2  \n",
            "Day_of_Week_6                                      0.0              2  \n",
            "Month_2                                            0.0              2  \n",
            "Month_3                                            0.0              2  \n",
            "Month_4                                            0.0              2  \n",
            "Month_5                                            0.0              2  \n",
            "Month_6                                            0.0              2  \n",
            "Month_7                                            0.0              2  \n",
            "Month_8                                            0.0              2  \n",
            "Month_9                                            0.0              2  \n",
            "Month_10                                           0.0              2  \n",
            "Month_11                                           0.0              2  \n",
            "Month_12                                           0.0              2  \n",
            "Year_2011                                          0.0              2  \n",
            "Year_2012                                          0.0              2  \n",
            "Year_2013                                          0.0              2  \n",
            "Year_2014                                          0.0              2  \n",
            "Year_2015                                          0.0              2  \n",
            "Year_2016                                          0.0              2  \n",
            "Year_2017                                          0.0              2  \n",
            "Year_2018                                          0.0              2  \n",
            "Year_2019                                          0.0              2  \n",
            "Year_2020                                          0.0              2  \n",
            "Year_2021                                          0.0              2  \n",
            "Year_2022                                          0.0              2  \n",
            "Year_2023                                          0.0              2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns=['Crm_Cd_Desc', 'Crime_Category', 'Crm_Cd', 'AREA_NAME', 'Rpt_Dist_No', 'TIME_OCC'], axis = 0)"
      ],
      "metadata": {
        "id": "Y5KqsQhx048-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithms LR"
      ],
      "metadata": {
        "id": "TVsyyml866n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the features and the target variable\n",
        "X = data.drop('Crime_Category_Code', axis=1)  # Features\n",
        "y = data['Crime_Category_Code']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the Logistic Regression model: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rZf6zUpZQe7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d220002-fe00-4b3a-d558-84b61667d728"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model: 73.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = log_reg.coef_[0]\n",
        "\n",
        "# Map coefficients to features\n",
        "feature_names = X_train.columns\n",
        "feature_impact = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(feature_impact)"
      ],
      "metadata": {
        "id": "gtOD15tQ73uO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31851e4f-a792-4405-9ad5-747bf0b1a43d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        Feature  Coefficient\n",
            "11                              Weapon_Reported     5.388364\n",
            "1                                      Part_1-2     1.438681\n",
            "14                   Region_Ethnic_Origin_Black     0.617185\n",
            "12                                   Vict_Sex_M     0.435521\n",
            "15  Region_Ethnic_Origin_Hispanic/Latin/Mexican     0.335833\n",
            "48                                    Year_2023     0.196827\n",
            "24                                Day_of_Week_6     0.153645\n",
            "46                                    Year_2021     0.151382\n",
            "42                                    Year_2017     0.144597\n",
            "3                                           LAT     0.139273\n",
            "35                                     Month_12     0.104244\n",
            "47                                    Year_2022     0.103906\n",
            "44                                    Year_2019     0.101152\n",
            "45                                    Year_2020     0.093404\n",
            "4                                           LON     0.078257\n",
            "26                                      Month_3     0.074860\n",
            "23                                Day_of_Week_5     0.069247\n",
            "28                                      Month_5     0.065939\n",
            "25                                      Month_2     0.054083\n",
            "34                                     Month_11     0.043316\n",
            "10                          Total_Precipitation     0.038373\n",
            "41                                    Year_2016     0.035368\n",
            "40                                    Year_2015     0.028741\n",
            "27                                      Month_4     0.017814\n",
            "6                                  Avg_Dewpoint     0.010649\n",
            "2                                      Vict_Age     0.007216\n",
            "43                                    Year_2018     0.006218\n",
            "29                                      Month_6     0.002355\n",
            "5                                      Avg_Temp    -0.000653\n",
            "7                                  Avg_Humidity    -0.004380\n",
            "0                                          AREA    -0.005446\n",
            "9                                  Avg_Pressure    -0.007523\n",
            "18                   Region_Ethnic_Origin_White    -0.012516\n",
            "8                                 Avg_Windspeed    -0.013177\n",
            "20                                Day_of_Week_2    -0.021564\n",
            "30                                      Month_7    -0.025764\n",
            "33                                     Month_10    -0.026062\n",
            "19                                Day_of_Week_1    -0.029412\n",
            "21                                Day_of_Week_3    -0.039293\n",
            "39                                    Year_2014    -0.048273\n",
            "22                                Day_of_Week_4    -0.055825\n",
            "31                                      Month_8    -0.056361\n",
            "32                                      Month_9    -0.063713\n",
            "37                                    Year_2012    -0.148119\n",
            "38                                    Year_2013    -0.152270\n",
            "16                   Region_Ethnic_Origin_Other    -0.191922\n",
            "36                                    Year_2011    -0.214345\n",
            "17                 Region_Ethnic_Origin_Unknown    -0.490548\n",
            "13                                   Vict_Sex_X    -0.966379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Hyperparameter grid\n",
        "# param_grid = {\n",
        "#     'C': np.logspace(-4, 4, 20),\n",
        "#     'penalty': ['l1', 'l2'],\n",
        "#     'solver': ['liblinear', 'saga']  # 'liblinear' and 'saga' work well with 'l1'\n",
        "# }\n",
        "\n",
        "# # Initialize the Grid Search model\n",
        "# grid_search = GridSearchCV(estimator=LogisticRegression(max_iter=1000), param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Best hyperparameters\n",
        "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# # Make predictions with the best model\n",
        "# y_pred_optimized = grid_search.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy\n",
        "# accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
        "# print(f\"Optimized Accuracy: {accuracy_optimized * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "uZK_xkc5oa9C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMGtWukJTPZZ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}